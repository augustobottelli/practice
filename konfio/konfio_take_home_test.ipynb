{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Konfio Take Home Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset attached (‘dataset.zip’) consists on two csv files: ‘users.csv’ containing the\n",
    "income, outcome and a label for 1000 users, and ‘credit_reports.csv’ containing all the\n",
    "accounts from the user’s credit reports . (Check the appendix A and B for the 1\n",
    "codebooks).\n",
    "Each user is labeled as 1 if the user was a good client and 0 if the user was a bad client\n",
    "\n",
    "1) Pick the best clients you will give a loan to, based on the model you created. It\n",
    "could be as complex as you decide (even as simpler as knock out rules), as long as\n",
    "the metrics support it\n",
    "\n",
    "2) Propose an amount to be lended to those clients and a term in which the loan will\n",
    "need to be paid back.\n",
    "\n",
    "3) Finally choose an anual interest rate the lended amount must have in order to be\n",
    "profitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Business Understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As almost every business, the main objective of commercial banks is to make money, how do they do this?\n",
    "Commercial banks use customer deposits to lend money to other individuals at a given interest rate. This means that for the bank to be profitable the bank needs that:\n",
    "- The interest rate interest rate charged for lending money (placement rate) needs to be higher than the interest rates of deposits (captive rate) (and higher than the inflation rate).\n",
    "- The borrowers pay all of its debt with its corresponding fees and interest.\n",
    "\n",
    "This means that the bank is interested in having models which:\n",
    "- Predicts with confidence when a person is not likely to repay a loan\n",
    "- Select users who are more likely to pay in order to offer them a loan\n",
    "\n",
    "For the first model the plan is to build a dataset and a label that exposes when a credit has 3 or more delayed payments and learn train a model which learns the patterns which cause this.\n",
    "This model will allow us to pick the best combinations of terms and amount to be lended by trying different combinations and choosing the one with the least probability of default.\n",
    "\n",
    "For the second model I tried 2 different approaches:\n",
    "- The first one involved doing a weighted average based on the features which I considered necessary for a client to be good (and weighted them accordingly) and ranked the users based on such formula without taking into account the label provided. Before doing so I applied a few transformations like taking the log and scaling the values between 0 and 1 for equal weight across features.\n",
    "- The second one involved a more common approach for the industry (but personally never heard of it before) and was to train a Logistic Regression replacing variables by its WoE (weight of evidence) and filtering them by their IV (information value). Afterwords, using a specific formula based on the regression coefficient and the features's WoE a scorecard was built in order to rank users. (https://weclouddata.com/student-project-credit-scoring-using-machine-learning/)\n",
    "\n",
    "The reason for this is mainly due to the fact that I observed that there were users who were labeled as good but had a really questionable credit history and fitting a model to an already labeled user felt odd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the annual interest interest in order to be profitable I used the model which predicts infractors. The key of the answers lies in \"profitable\". As mentioned before, assuming total certainty in payments, a commercial bank is profitable if it has a rate diferential between its active and passive interest rates but the fact that in the real world uncertainty exists (in the form of default), I considered that profitability should also account for this issue. This is the reason why I decided to model the \"profitable\" interest rate as $$i_t = p_t + \\left(\\frac{1}{P(Y=0|X)}\\right)^2$$ where $p_t$ is the passive interest rate, $\\left(\\frac{1}{P(Y=0|X)}\\right)^2$ is the risk premium and $P(Y=0|X)$ is the probabily of NOT being an infractor (having 3 or more payments due).\n",
    "\n",
    "I searched for values to use for $p_t$ and found out that in Mexico the current it has an annual rate that bank's pay for deposits is aproximately 3%. Also I searched for loans interest rates in Mexico and found out that [BBVA offers an annual interest rate between 25,75% and 45,75%](https://www.bbva.mx/personas/productos/creditos/prestamos-personales/prestamo-personal-inmediato.html#:~:text=25.75%25%20hasta%2045.75%25%20sin%20IVA,de%20tu%20evaluaci%C3%B3n%20de%20cr%C3%A9dito.) for loans between 3k and 750k so my formula was adjusted in order to at least try to yield similar results.\n",
    "\n",
    "In order to do so, the interest rate could also be defined as $$i_t = i^B_t + \\left(\\frac{1}{P(Y=0|X)}\\right)$$ where $i^B_t$ is the minimum interest rate determined by another bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* From now on, the comments are in Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install seaborn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install lightgbm\n",
    "!pip3 install lightgbm\n",
    "!pip3 install pandas-profiling\n",
    "!pip2 install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime, date, timedelta\n",
    "import unidecode\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    LabelEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"users.csv\")\n",
    "credit_reports = pd.read_csv(\"credit_reports.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_report = ProfileReport(users)\n",
    "credit_reports_report = ProfileReport(credit_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de cuenta:\n",
    "- Revolvente: https://economipedia.com/definiciones/credito-revolving.html\n",
    "- Prendario: https://economipedia.com/definiciones/credito-pignoraticio.html\n",
    "- Hipoteca: https://economipedia.com/definiciones/hipoteca.html\n",
    "- Quirografiario: https://economipedia.com/definiciones/prestamo-quirografario.html\n",
    "\n",
    "Tipos de credito:\n",
    "    \n",
    "- Linea de Credito: https://economipedia.com/definiciones/linea-de-credito.html\n",
    "- Prestamo personal: https://economipedia.com/definiciones/credito-personal.html\n",
    "- Tarjeta de Credito: https://economipedia.com/definiciones/tarjeta-de-credito.html\n",
    "- Credito fiscal: https://economipedia.com/definiciones/incentivo-fiscal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que el dataset tiene informacion nula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observemos que pasa con `total_credit_payments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"account_type == 'Revolvente' \")[\n",
    "    \"total_credit_payments\"\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[credit_reports[\"total_credit_payments\"].isna()][\n",
    "    [\"account_type\", \"credit_type\", \"total_credit_payments\", \"account_closing_date\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que son todos creditos revolventes / sin limite preestablecido que usualmente no tienen pagos preacordados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la distribucion de la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"account_type == 'Revolvente'\")[\"total_credit_payments\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que no tienen fecha de fin (intuyo que son lineas de credito que siguen abiertas al momento que se creo el dataset) y que la distribucion señala que la gran mayoria de estos creditos tienen cantidad de pagos = a 0, voy a completar los valores faltantes con dicho valor (la moda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"total_credit_payments\"] = credit_reports[\n",
    "    \"total_credit_payments\"\n",
    "].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observemos `payment_frequency`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[credit_reports[\"payment_frequency\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"payment_frequency\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"user_id == 742\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\n",
    "    \"institution == 'COOPERATIVA' and account_type == 'Pagos Fijos' and credit_type == 'Préstamo Personal '\"\n",
    ")[\"payment_frequency\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la forma de pago mas usual para dicha institucion, linea de credito y tipo de cuenta es mensual. Ademas, el usuario opto siempre por pagos mensuales.\n",
    "De todas maneras dado que tenemos un closing_date de aproximadamente 6 meses de diferencia (tiene sentido que sean 2 pagos trimestrales), voy a optar por eliminar la observacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports[\n",
    "    ~credit_reports[\"payment_frequency\"].isna()\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observemos `amount_to_pay_next_payment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[credit_reports[\"amount_to_pay_next_payment\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun entiendo `amount_to_pay_next_payment` va a estar influenciada por `maximum credit limit` y `total_credit_payments`, es decir:\n",
    "\n",
    "- `amount_to_pay_next_payment` = `maximum_credit_amount` * (1 + i) / `total_credit_payments` donde i puede ser una tasa catorcenal, mensual, quincenal, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareceria ser posible sacar la tasa de interes de este modo para el caso de prestamos personales con pagos fijos que no hayan tenido ningun tipo de deuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la formula anterior podemos saber que:\n",
    "    \n",
    "- i_t = ((`amount_to_pay_next_payment` * `total_credit_payments`) / `maximum_credit_amount`) - 1\n",
    "\n",
    "(De todas maneras no voy a usar este dato porque los resultados no tenian sentido (anexo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ante la duda voy a optar por eliminar estas observaciones que contienen datos faltantes que parecen irrecuperables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports[\n",
    "    ~credit_reports[\"amount_to_pay_next_payment\"].isna()\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obervamos: `maximum_credit_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[~credit_reports[\"maximum_credit_amount\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podria recuperar el valor asumiendo que maximum_credit_amount == amount_to_pay_next_payment, ante la duda, prefiero eliminar la observacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports[\n",
    "    ~credit_reports[\"maximum_credit_amount\"].isna()\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos: `credit_limit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo que me llama la atencion de esta variable es que esta variable el anexo la define como: \n",
    ">Credit limit for this account\n",
    "\n",
    "Pero despues tenemos la variable `maximum_credit_amount` que significa\n",
    "> Maximum amount of credit used by the consumer.\n",
    "\n",
    "Asi que en teoria maximum_credit_amount <= credit_limit, validemoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"maximum_credit_amount <= credit_limit\").shape[\n",
    "    0\n",
    "] / credit_reports.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(credit_reports.credit_limit + 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.credit_limit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo el 42% de los datos cumplem con esa hipotesis, posiblemente porque 43% de las observaciones tienen credit_limit == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\n",
    "    \"account_type == 'Pagos Fijos' and credit_type == 'Préstamo Personal ' and credit_limit != 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareceria ser que en los casos en los que no es 0 el credit_limit es igual al maximum_credit_amount. Tiene sentido dado que en un Prestamo Personal no exite tal cosa como un credito limite sino que el monto a pagar esta establecido previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.corr()[\"credit_limit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\n",
    "    \"account_type == 'Pagos Fijos' and credit_type == 'Préstamo Personal ' and credit_limit != 0\"\n",
    ").apply(lambda x: x.maximum_credit_amount == x.credit_limit, axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 93% de las veces se valida esta informacion.\n",
    "\n",
    "De todas maneras antes la diversidad de tipos de credito prefiero directamente eliminar las observaciones con datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\n",
    "    \"account_type == 'Pagos Fijos' and credit_type == 'Préstamo Personal '\"\n",
    ")[[\"maximum_credit_amount\", \"credit_limit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports[~credit_reports[\"credit_limit\"].isna()].reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports[\n",
    "    ~credit_reports[\"payment_frequency\"].isna()\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"current_balance == 0 and number_of_payments_due > 0\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entiendo muy bien el funcionamiento de current_balance, figura que todo esta pago cuando tiene deudas pendientes, voy a optar por eliminarla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.query(\"total_credit_payments == 0\")[\"account_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que la consigna consulta sobre prestamos y para simplificar el analisis, voy a tomar solo el historial crediticio para Prestamos Personales con Pagos Fijos que hayan sido utilizados.\n",
    "Ademas, voy a filtrar por las observaciones que tengan total_credit_payments > a 0 dado que no le encuentro sentido a que sea == a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports = credit_reports.query(\n",
    "    \"credit_type == 'Préstamo Personal ' and total_credit_payments != 0 and maximum_credit_amount > 0\"\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"account_opening_date\"] = pd.to_datetime(\n",
    "    credit_reports.account_opening_date\n",
    ")\n",
    "credit_reports[\"account_closing_date\"] = pd.to_datetime(\n",
    "    credit_reports[\"account_closing_date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"payments_due_ratio\"] = (\n",
    "    credit_reports[\"number_of_payments_due\"] / credit_reports[\"total_credit_payments\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"loan_amount\"] = np.where(\n",
    "    credit_reports[\"credit_limit\"] > 0,\n",
    "    credit_reports[\"credit_limit\"],\n",
    "    credit_reports[\"maximum_credit_amount\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"worst_delinquent_payments\"] = np.where(\n",
    "    credit_reports[\"worst_delinquency\"] > credit_reports[\"number_of_payments_due\"],\n",
    "    credit_reports[\"worst_delinquency\"],\n",
    "    credit_reports[\"number_of_payments_due\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"infractor\"] = np.where(\n",
    "    credit_reports[\"worst_delinquent_payments\"] > 3, 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_frequency = {\n",
    "    \"mensual\": 30,\n",
    "    \"semanal\": 7,\n",
    "    \"una sola exhibicion\": 1,\n",
    "    \"quincenal\": 15,\n",
    "    \"catorcenal\": 14,\n",
    "    \"anual\": 360,\n",
    "    \"trimestral\": 90,\n",
    "    \"bimestral\": 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"payment_frequency_delta\"] = credit_reports[\"payment_frequency\"].apply(\n",
    "    lambda x: timedelta(mapping_frequency.get(unidecode.unidecode(x.lower())))\n",
    ")\n",
    "\n",
    "credit_reports[\"payment_frequency_days\"] = credit_reports[\n",
    "    \"payment_frequency_delta\"\n",
    "].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"expected_end\"] = credit_reports[\"account_opening_date\"] + (\n",
    "    credit_reports[\"total_credit_payments\"] * credit_reports[\"payment_frequency_delta\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"pre_cancelled\"] = (\n",
    "    credit_reports[\"account_closing_date\"] < credit_reports[\"expected_end\"]\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports[\"duration_days\"] = (\n",
    "    credit_reports[\"expected_end\"] - credit_reports[\"account_opening_date\"]\n",
    ").dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.rename(columns={\"id\": \"user_id\"})\n",
    "users = users.rename(columns={\"class\": \"is_good\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_credit_reports = pd.merge(users, credit_reports, on=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_reports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_credit_reports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features = users.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    #     \"min\": [\"worst_delinquency_past_due_balance\"],\n",
    "    #     \"max\": [\"loan_amount\", \"worst_delinquent_payments\"],\n",
    "    \"mean\": [\n",
    "        \"loan_amount\",\n",
    "        \"worst_delinquent_payments\",\n",
    "        \"infractor\",\n",
    "        \"payment_frequency_days\",\n",
    "        \"pre_cancelled\",\n",
    "        \"duration_days\",\n",
    "    ],\n",
    "    \"count\": [\"loan_amount\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agg, features in features_map.items():\n",
    "    for feature in features:\n",
    "        if agg == \"min\":\n",
    "            users_features[f\"{agg}_{feature}\"] = full_credit_reports.groupby(\"user_id\")[\n",
    "                feature\n",
    "            ].min()\n",
    "        elif agg == \"mean\":\n",
    "            users_features[f\"{agg}_{feature}\"] = full_credit_reports.groupby(\"user_id\")[\n",
    "                feature\n",
    "            ].mean()\n",
    "        elif agg == \"max\":\n",
    "            users_features[f\"{agg}_{feature}\"] = full_credit_reports.groupby(\"user_id\")[\n",
    "                feature\n",
    "            ].max()\n",
    "        elif agg == \"count\":\n",
    "            users_features[f\"{agg}_{feature}\"] = full_credit_reports.groupby(\"user_id\")[\n",
    "                feature\n",
    "            ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features[\"monthly_net_income\"] = (\n",
    "    users_features[\"monthly_income\"] - users_features[\"monthly_outcome\"]\n",
    ")\n",
    "users_features = users_features.drop(\n",
    "    [\"user_id\", \"monthly_income\", \"monthly_outcome\"], axis=1\n",
    ")\n",
    "users_features = users_features.dropna()  # Drop users without credit records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features.query(\"is_good == 1\").sort_values(\n",
    "    [\"mean_worst_delinquent_payments\", \"mean_infractor\"], ascending=False\n",
    ")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me parece raro que se cataloguen como buenos usuarios que tienen un histora crediticio tan malo. Concentremesnos en el usuario 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_credit_reports.query(\"user_id == 400\")[\n",
    "    [\n",
    "        \"user_id\",\n",
    "        \"maximum_credit_amount\",\n",
    "        \"number_of_payments_due\",\n",
    "        \"worst_delinquency\",\n",
    "        \"worst_delinquency_past_due_balance\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El usuario incumplio pagos en sus 3 creditos por casi la totalidad de lo usado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_users = users_features.drop(\"is_good\", axis=1)\n",
    "y_users = users_features[\"is_good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    X_users.corr(),\n",
    "    xticklabels=X_users.corr().columns,\n",
    "    yticklabels=X_users.corr().columns,\n",
    "    center=0,\n",
    "    cmap=sns.diverging_palette(220, 20, as_cmap=True),\n",
    "    annot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infractor features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo features historicas laggeadas y elimino features inexistentes al momento de evaluar para evitar cualquier tipo de data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features = full_credit_reports.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features = infractor_features.sort_values(\n",
    "    [\"user_id\", \"account_opening_date\"]\n",
    ").reset_index(\n",
    "    drop=True\n",
    ")  # Ordeno por user y fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"historic_total_loans_granted\"] = (\n",
    "    infractor_features.groupby([\"user_id\"])[\"loan_amount\"]\n",
    "    .apply(lambda x: x.shift().expanding().count())\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"historic_worst_delinquent_payments\"] = (\n",
    "    infractor_features.groupby([\"user_id\"])[\"worst_delinquent_payments\"]\n",
    "    .apply(lambda x: x.shift().expanding().max())\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"historic_infractor_rate\"] = (\n",
    "    infractor_features.groupby([\"user_id\"])[\"infractor\"]\n",
    "    .apply(lambda x: x.shift().expanding().mean())\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"historic_pre_cancelled_rate\"] = (\n",
    "    infractor_features.groupby([\"user_id\"])[\"pre_cancelled\"]\n",
    "    .apply(lambda x: x.shift().expanding().mean())\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"loan_created_year\"] = infractor_features[\n",
    "    \"account_opening_date\"\n",
    "].dt.year.astype(str)\n",
    "infractor_features[\"loan_created_month\"] = infractor_features[\n",
    "    \"account_opening_date\"\n",
    "].dt.month.astype(str)\n",
    "infractor_features[\"loan_created_weekday\"] = infractor_features[\n",
    "    \"account_opening_date\"\n",
    "].dt.weekday.astype(str)\n",
    "infractor_features[\"loan_expected_end_year\"] = infractor_features[\n",
    "    \"expected_end\"\n",
    "].dt.year.astype(str)\n",
    "infractor_features[\"loan_expected_end_month\"] = infractor_features[\n",
    "    \"expected_end\"\n",
    "].dt.month.astype(str)\n",
    "infractor_features[\"loan_expected_end_weekday\"] = infractor_features[\n",
    "    \"expected_end\"\n",
    "].dt.weekday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features = infractor_features.drop(\n",
    "    [\n",
    "        \"current_balance\",\n",
    "        \"past_due_balance\",\n",
    "        \"worst_delinquency_date\",\n",
    "        \"payment_frequency\",\n",
    "        \"payment_frequency_delta\",\n",
    "        \"worst_delinquency\",\n",
    "        \"worst_delinquent_payments\",\n",
    "        \"expected_end\",\n",
    "        \"account_opening_date\",\n",
    "        \"account_closing_date\",\n",
    "        \"pre_cancelled\",\n",
    "        \"payments_due_ratio\",\n",
    "        \"number_of_payments_due\",\n",
    "        \"worst_delinquency_past_due_balance\",\n",
    "        \"amount_to_pay_next_payment\",\n",
    "        \"maximum_credit_amount\",\n",
    "        \"credit_limit\",\n",
    "        \"is_good\",\n",
    "        \"account_type\",\n",
    "        \"credit_type\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_infractor = infractor_features.drop([\"infractor\", \"user_id\"], axis=1)\n",
    "y_infractor = infractor_features[\"infractor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    X_infractor.corr(),\n",
    "    xticklabels=X_infractor.corr().columns,\n",
    "    yticklabels=X_infractor.corr().columns,\n",
    "    center=0,\n",
    "    cmap=sns.diverging_palette(220, 20, as_cmap=True),\n",
    "    annot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_users_log = X_users.apply(lambda x: np.where(x > 0, np.log(x + 1), 0))\n",
    "\n",
    "X_users_scaled = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(X_users_log),\n",
    "    columns=X_users.columns,\n",
    "    index=X_users_log.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_users_scaled[\"score\"] = X_users_scaled.apply(\n",
    "    lambda x: (x.mean_loan_amount * 0.5)\n",
    "    - (0.8 * x.mean_worst_delinquent_payments)\n",
    "    - (0.8 * x.mean_infractor)\n",
    "    + (0.1 * x.monthly_net_income)\n",
    "    + (0.3 * x.count_loan_amount),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_users_scoring = X_users_scaled.sort_values(\"score\", ascending=False)[\n",
    "    :10\n",
    "].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(X_users, X_users_scaled[[\"score\"]], left_index=True, right_index=True).loc[\n",
    "    best_users_scoring\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tiene mucho sentido el score, son usuarios que nunca defaultearon, tomaron creditos grandes y los repagaron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_woe_features(dataset, variable_names, target_name, n_bins=10):\n",
    "    data = dataset.copy()\n",
    "    woe_features = {}\n",
    "    for variable_name in variable_names:\n",
    "        binned_feature, bins_ = pd.qcut(\n",
    "            data[variable_name], n_bins, retbins=True, duplicates=\"drop\"\n",
    "        )\n",
    "        binned_variable_name = f\"{variable_name}_bins\"\n",
    "        data[binned_variable_name] = binned_feature\n",
    "        tmp = data.groupby(binned_variable_name, as_index=False).agg(\n",
    "            {target_name: [\"count\", \"sum\"]}\n",
    "        )\n",
    "        tmp.columns = [f\"{variable_name}_bins\", \"N\", \"positive\"]\n",
    "        tmp[\"positive_rate\"] = tmp.positive / tmp.positive.sum()\n",
    "        tmp[\"negative\"] = tmp.N - tmp.positive\n",
    "        tmp[\"negative_rate\"] = tmp.negative / tmp.negative.sum()\n",
    "        tmp[f\"WOE_{variable_name}\"] = np.log(tmp.positive_rate / tmp.negative_rate)\n",
    "        tmp[f\"IV_{variable_name}\"] = (tmp.positive_rate - tmp.negative_rate) * tmp[\n",
    "            f\"WOE_{variable_name}\"\n",
    "        ]\n",
    "        woe_features[variable_name] = (\n",
    "            tmp[\n",
    "                [f\"{variable_name}_bins\", f\"WOE_{variable_name}\", f\"IV_{variable_name}\"]\n",
    "            ],\n",
    "            bins_,\n",
    "        )\n",
    "    return woe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = users_features.columns[1:]\n",
    "target = \"is_good\"\n",
    "woe_features = build_woe_features(users_features, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(data, woe_dfs, features, target):\n",
    "    df = data.copy()\n",
    "    for feature in features:\n",
    "        woe_df, bins = woe_dfs.get(feature)\n",
    "        if woe_df[f\"IV_{feature}\"].sum() < 0.15:\n",
    "            logging.warning(f\"{feature} discarded -> IV < 0.15\")\n",
    "            continue\n",
    "        df[f\"{feature}_bins\"] = pd.cut(df[feature], bins, include_lowest=True)\n",
    "        df = pd.merge(df, woe_df, on=f\"{feature}_bins\", how=\"left\")\n",
    "    cols = [column for column in df.columns if column.startswith(\"WOE\")] + [target]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = transform_df(users_features, woe_features, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_df.drop(target, axis=1)\n",
    "y = transformed_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset esta balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# building the model and fitting the data\n",
    "log_reg = sm.Logit(y_train, X_train).fit()\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ni WOE_mean_infractor ni WOE_mean_payment_frequency days son significativas, veamos que tan bien predice el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(reg, X_test, y_test, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_users = X_test.copy()\n",
    "check_users[\"real\"] = y_test\n",
    "check_users[\"prob\"] = reg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.distplot(check_users.query(\"real == 0\")[\"prob\"], label=\"negative\", bins=25)\n",
    "sns.distplot(check_users.query(\"real == 1\")[\"prob\"], label=\"positive\", bins=25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene una performance razonable aunque la distincion de clases no pareceria estar muy determinada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construyamos el scorecard a partir del modelo entrenado, recordemos que la formula para cada feature era:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Score_i= (\\beta_i * WoE_i + \\frac{\\alpha}{n}) * Factor + \\frac{Offset}{n} $$\n",
    "\n",
    "Donde:\n",
    "- $\\beta$ -> coeficiente de la regresion\n",
    "- $\\alpha$ -> el intercept de la regresion\n",
    "- WoE -> Weight of Evidence de la feature\n",
    "- n -> la cantidad de features del modelo\n",
    "- Factor -> pdo (points to double the odds) /Ln(2) \n",
    "- Offset = Score - (Factor × ln(Odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "pdo = 20\n",
    "factor = pdo / np.log(2)\n",
    "offset = 200\n",
    "# import ipdb; ipdb.set_trace()\n",
    "coefs_dict = dict(zip(X, reg.coef_[0]))\n",
    "coefs_dict[\"intercept\"] = reg.intercept_[0]\n",
    "results = transformed_df.copy()\n",
    "for feature in X.columns.tolist():\n",
    "    feature_ = \"_\".join(feature.split(\"_\")[1:])\n",
    "    df = woe_features.get(feature_, ())[0]\n",
    "    coef = coefs_dict.get(feature)\n",
    "    intercept = coefs_dict.get(\"intercept\")\n",
    "    df[\"score\"] = df[f\"WOE_{feature_}\"].apply(\n",
    "        lambda x: (x * coef + (intercept / n) * factor + (offset / n))\n",
    "    )\n",
    "    results = pd.merge(\n",
    "        results,\n",
    "        woe_features.get(feature_)[0][[f\"WOE_{feature_}\", \"score\"]],\n",
    "        on=f\"WOE_{feature_}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = [col for col in results.columns if col.startswith(\"score\")]\n",
    "score = results[score_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = X_users.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[\"score\"] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.sort_values(\"score\", ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_users_woe = check.sort_values(\"score\", ascending=False)[:10].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features[\"infractor\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas estan muy desbalanceadas asi que hay 2 posibilidades:\n",
    "- Samplear algunas observaciones negativas para que queden mejor distribuidas\n",
    "- Sobresamplear utilizando tecnicas como [SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "Dado que estamos utilizando features que tienen dependencia temporal me surgio la duda si era correcto sobresamplear asi que opte por subsamplear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = infractor_features.query(\"infractor == 0\").sample(800)\n",
    "pos = infractor_features.query(\"infractor == 1\")\n",
    "infractor_features_subsample = neg.append(pos).sort_index()  # Avoid shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infractor_features_subsample[\"infractor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.75\n",
    "n_obs = int(train_size * infractor_features_subsample.shape[0])\n",
    "train_infractor = infractor_features_subsample[:n_obs]\n",
    "test_infractor = infractor_features_subsample[n_obs + 1 :]\n",
    "X_train_infractor = train_infractor.drop([\"infractor\", \"user_id\"], axis=1)\n",
    "y_train_infractor = train_infractor[\"infractor\"]\n",
    "X_test_infractor = test_infractor.drop([\"infractor\", \"user_id\"], axis=1)\n",
    "y_test_infractor = test_infractor[\"infractor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(numeric_features, categorical_features, model):\n",
    "    numeric_transformer = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"imputer\",\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    categorical_transformer = Pipeline(\n",
    "        [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"estimator\", model)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"institution\",\n",
    "    \"payment_frequency_days\",\n",
    "    \"loan_created_year\",\n",
    "    \"loan_created_month\",\n",
    "    \"loan_created_weekday\",\n",
    "    \"loan_expected_end_year\",\n",
    "    \"loan_expected_end_month\",\n",
    "    \"loan_expected_end_weekday\",\n",
    "]\n",
    "numerical_features = X_train_infractor.drop(\n",
    "    categorical_features, axis=1\n",
    ").columns.tolist()\n",
    "# model = GridSearchCV(LGBMClassifier(), params__, cv=5, n_jobs=-1)\n",
    "pipe = build_pipeline(numerical_features, categorical_features, LGBMClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_infractor, y_train_infractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_infractor = X_test_infractor.copy()\n",
    "check_infractor[\"preds\"] = pipe.predict(X_test_infractor)\n",
    "check_infractor[\"prob\"] = pipe.predict_proba(X_test_infractor)[:, 1]\n",
    "check_infractor[\"real\"] = y_test_infractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, X_test_infractor, y_test_infractor, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(check_infractor[\"real\"], check_infractor[\"preds\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.distplot(check_infractor.query(\"real == 0\")[\"prob\"], label=\"negative\", bins=25)\n",
    "sns.distplot(check_infractor.query(\"real == 1\")[\"prob\"], label=\"positive\", bins=25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_feature_importance(numeric_features, categorical_features, pipeline):\n",
    "    ohe_feature_names = (\n",
    "        pipeline.steps[0][1]\n",
    "        .transformers_[1][1]\n",
    "        .steps[1][1]\n",
    "        .get_feature_names(categorical_features)\n",
    "    )\n",
    "    feature_importances = pipeline.steps[1][1].feature_importances_\n",
    "    cols = list(numeric_features) + list(ohe_feature_names)\n",
    "    f_i = list(zip(cols, feature_importances))\n",
    "    feat_imp = pd.DataFrame(f_i, columns=[\"feature_names\", \"importance\"])\n",
    "    feat_imp = feat_imp.sort_values(\"importance\", ascending=False).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pipeline_feature_importance(numerical_features, categorical_features, pipe)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion vamos a construir las features que representarian como funcionaria nuestra logica en produccion y determinar, segun los usuarios que elegimos en el punto anterior, que monto, que tasa y a que plazo le ofreceriamos un prestamo. Dado que construimos dos modelos para seleccionar usuarios, vamos a probarlo para ambos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_woe = (\n",
    "    infractor_features.groupby(\"user_id\")\n",
    "    .max()[\n",
    "        [\n",
    "            \"monthly_income\",\n",
    "            \"monthly_outcome\",\n",
    "            \"loan_amount\",\n",
    "            \"historic_total_loans_granted\",\n",
    "            \"historic_worst_delinquent_payments\",\n",
    "            \"historic_infractor_rate\",\n",
    "            \"historic_pre_cancelled_rate\",\n",
    "        ]\n",
    "    ]\n",
    "    .reset_index()\n",
    "    .query(f\"user_id in {best_users_woe}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_scoring = (\n",
    "    infractor_features.groupby(\"user_id\")\n",
    "    .max()[\n",
    "        [\n",
    "            \"monthly_income\",\n",
    "            \"monthly_outcome\",\n",
    "            \"loan_amount\",\n",
    "            \"historic_total_loans_granted\",\n",
    "            \"historic_worst_delinquent_payments\",\n",
    "            \"historic_infractor_rate\",\n",
    "            \"historic_pre_cancelled_rate\",\n",
    "        ]\n",
    "    ]\n",
    "    .reset_index()\n",
    "    .query(f\"user_id in {best_users_scoring}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_scoring.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construimos las features base asociadas a la institucion y el tipo de credito que se otorga para probar con distintos tipos y quedarnos con la mejor combinacion\n",
    "- Institucion que otorga el credito: Konfio\n",
    "- La cantidad que se le va a ofrecer: maxima cantidad prestada y completada historica\n",
    "- Duracion del credito: vamos a probar con 1, 2 y 3 años\n",
    "- Frecuencia de pago: vamos a probar con todas las vistas anteriormente (semanal, quincenal, mensual, anual, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "today = date.today()\n",
    "for payment_frequency in [30, 7, 15, 14, 90, 360, 60]:\n",
    "    for duration_days in [360, 360 * 2, 360 * 3]:\n",
    "        data.append(\n",
    "            dict(\n",
    "                institution=\"KONFIO\",\n",
    "                payment_frequency_days=payment_frequency,\n",
    "                duration_days=duration_days,\n",
    "                total_credit_payments=duration_days / payment_frequency,\n",
    "                loan_created_year=today.year,\n",
    "                loan_created_month=today.month,\n",
    "                loan_created_weekday=today.weekday(),\n",
    "                loan_expected_end_year=(today + timedelta(days=duration_days)).year,\n",
    "                loan_expected_end_month=(today + timedelta(days=duration_days)).month,\n",
    "                loan_expected_end_weekday=(\n",
    "                    today + timedelta(days=duration_days)\n",
    "                ).weekday(),\n",
    "            )\n",
    "        )\n",
    "base_data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya tenemos todas las features necesarias para evaluar en nuestro modelo. Generemos el dataset con todas las combinacion de frequencia de pago + duracion del credito que pusimos anteriormente para los usuarios elegidos por el modelo de scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_records = base_data_df.to_dict(orient=\"records\")\n",
    "user_records_scoring = user_features_scoring.drop(\"user_id\", axis=1).to_dict(\n",
    "    orient=\"records\"\n",
    ")\n",
    "user_records_woe = user_features_woe.drop(\"user_id\", axis=1).to_dict(orient=\"records\")\n",
    "\n",
    "observations_scoring = pd.DataFrame(\n",
    "    [\n",
    "        {**base_data_record, **user_record}\n",
    "        for base_data_record in base_data_records\n",
    "        for user_record in user_records_scoring\n",
    "    ]\n",
    ")\n",
    "observations_woe = pd.DataFrame(\n",
    "    [\n",
    "        {**base_data_record, **user_record}\n",
    "        for base_data_record in base_data_records\n",
    "        for user_record in user_records_woe\n",
    "    ]\n",
    ")\n",
    "observations_scoring = observations_scoring[X_infractor.columns]\n",
    "observations_woe = observations_woe[X_infractor.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos sobre el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_check_scoring = observations_scoring.copy()\n",
    "observations_check_scoring[\"preds\"] = pipe.predict_proba(observations_scoring)[:, 0]\n",
    "\n",
    "observations_check_woe = observations_woe.copy()\n",
    "observations_check_woe[\"preds\"] = pipe.predict_proba(observations_woe)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y nos quedamos con la combinacion que devuelva la MAYOR probabilidad de NO ser un infractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combinations_woe = (\n",
    "    observations_check_woe.groupby([\"monthly_income\", \"monthly_outcome\"])\n",
    "    .idxmax()[\"preds\"]\n",
    "    .values.tolist()\n",
    ")\n",
    "best_combinations_scoring = (\n",
    "    observations_check_scoring.groupby([\"monthly_income\", \"monthly_outcome\"])\n",
    "    .idxmax()[\"preds\"]\n",
    "    .values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_givers_woe = observations_check_woe.loc[best_combinations_woe]\n",
    "loan_givers_scoring = observations_check_scoring.loc[best_combinations_scoring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_givers_woe[\"anual_interest_rate\"] = 0.25 * (1 / loan_givers_woe[\"preds\"])\n",
    "loan_givers_scoring[\"anual_interest_rate\"] = 0.25 * (1 / loan_givers_scoring[\"preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_givers_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_givers_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es llamativo el hecho de que el modelo prediga que van a ser infractores algunos de los usuarios seleccionados previamente (para ambas metodologias) me quedaria tratar de entender de donde puede surgir dicha discrepancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos 2 metodologias para elegir \"mejores usuarios\" y un modelo para medir la probabilidad de incumplir los pagos de un credito y en base a eso calcular una tasa de interes anual que se ajuste a dicha probabilidad. Ambos modelos tienen performance razonables, quedaria ver si la logica es extensible a otros tipos de creditos y no solo prestamos personales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **< Anexo >**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = credit_reports.query(\n",
    "    \"\"\" \n",
    "    amount_to_pay_next_payment != 0 and \\\n",
    "    current_balance != 0 and \\\n",
    "    total_credit_payments > 0 and \\\n",
    "    credit_type == 'Préstamo Personal ' and \\\n",
    "    worst_delinquency == 0 and \\\n",
    "    number_of_payments_due == 0 and \\\n",
    "    past_due_balance == 0\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"interest_rate\"] = tmp.apply(\n",
    "    lambda x: (\n",
    "        (x.amount_to_pay_next_payment * x.total_credit_payments)\n",
    "        / x.maximum_credit_amount\n",
    "    )\n",
    "    - 1,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(tmp.query(\"institution == 'KONFIO'\")[\"interest_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"interest_rate\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, observo tasas razonables pero tambien veo casos que me hacen dudar si la logica que estoy siguiendo es correcta, asi que voy a dejar de profundizar sobre este aspecto porque no voy a utilizar dicha informacion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
