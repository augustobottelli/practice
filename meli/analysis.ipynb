{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from math import ceil\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas_profiling import ProfileReport\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = cpu_count() # Get computer avaiable threads\n",
    "thread_pool = ThreadPool(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_INFO = dict(app_id=7214923947282925,\n",
    "                secret_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH = {\"refresh_token\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.mercadolibre.com/\"\n",
    "MAX_OFFSET = 1000\n",
    "OFFSET = 50\n",
    "MAX_REQUESTS = ceil(MAX_OFFSET / OFFSET)\n",
    "PRECIO_DOLAR = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(endpoint, filter_id=None , attr=None, query_params={}):\n",
    "    args = list(filter(lambda x: x is not None, [endpoint, filter_id, attr]))\n",
    "    query = BASE_URL + \"/\".join(args) + (\"?\" if query_params else \"\")\n",
    "    query += \"&\".join(\n",
    "        f\"{key}={value}\"\n",
    "        for key, value in query_params.items()\n",
    "        if query_params and (key and value) is not None\n",
    "    )\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(app_id, secret_key, refresh_token):\n",
    "    params = dict(endpoint= \"oauth\",\n",
    "                  attr = \"token\")\n",
    "    params[\"query_params\"] = {\"grant_type\": \"refresh_token\",\n",
    "                             \"client_id\": app_id,\n",
    "                             \"client_secret\": secret_key,\n",
    "                             \"refresh_token\": refresh_token}\n",
    "    query = parse_query(**params)\n",
    "    req = requests.post(query)\n",
    "    resp = req.json()\n",
    "    token = resp.get(\"access_token\")\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_category(response, query_params):\n",
    "    if query_params[\"category\"] is None:\n",
    "        raise Exception(\"A category must me supplied\")\n",
    "    for result in response['results']:\n",
    "        result[\"main_category\"] = query_params[\"category\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_api(endpoint, filter_id=None, attr=None, query_params={}, include_category=False):\n",
    "    \"\"\"General function to query the API\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : str\n",
    "        Main API endpoint\n",
    "    filter_id : str, optional\n",
    "        Filter id (e.g $SITE_ID, $ITEM_ID) required for some endpoints, by default None\n",
    "    attr : str, optional\n",
    "        Attribute to extract from base response, by default None\n",
    "    query_params : dict, optional\n",
    "        Query values, parameters, and filters, by default {}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Json with API response\n",
    "    \"\"\"\n",
    "    adapter = HTTPAdapter(max_retries=Retry(total=3))\n",
    "    session = requests.Session()\n",
    "    session.mount(\"https://\", adapter)\n",
    "    query = parse_query(endpoint, filter_id, attr, query_params)\n",
    "    logging.debug(f\"Querying {query}\")\n",
    "    resp = session.get(query, timeout=20)\n",
    "    if resp.ok:\n",
    "        response = resp.json()\n",
    "        if include_category:\n",
    "            response = add_main_category(response, query_params)\n",
    "        return response\n",
    "    else:\n",
    "        raise Exception(resp.json().get(\"message\", \"\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_results(endpoint, filter_id, attr, query_params, include_category, results=[]):\n",
    "    query_params = query_params.copy()\n",
    "    for current_offset in range(0, MAX_OFFSET+1, OFFSET):\n",
    "        logging.debug(f\"Request {int(current_offset/OFFSET)} from {MAX_REQUESTS}\")\n",
    "        query_params['offset'] = current_offset\n",
    "        info = query_api(endpoint, filter_id, attr, query_params, include_category)\n",
    "        try:\n",
    "            results += info['results']\n",
    "        except Exception:\n",
    "            logging.exception(\"Error fetching data\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_subcategories(categories):\n",
    "    full_cats = {}\n",
    "    for i, category in enumerate(categories):\n",
    "        logging.debug(f\"Category {i} of {len(categories)}\")\n",
    "        category_id = category['id']\n",
    "        resp = query_api(endpoint=\"categories\", filter_id=category_id)\n",
    "        subcats = [subcat.get(\"id\") for subcat in resp['children_categories']]\n",
    "        full_cats[category_id] = subcats\n",
    "    return full_cats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(endpoint, filter_id, attr, full_cats, include_category, get_subcats=False):\n",
    "    data = []\n",
    "    if get_subcats:\n",
    "        cats = list(chain(*full_cats.values()))\n",
    "    else:\n",
    "        cats = list(full_cats.keys())\n",
    "    query_params = [{\"category\": cat, \"access_token\": TOKEN} for cat in cats]\n",
    "    try:\n",
    "        thread_pool.map(lambda x: get_max_results(endpoint, filter_id, attr, x, include_category, data), query_params)\n",
    "    except Exception:\n",
    "        logging.exception(\"A request failed\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = get_token(APP_INFO['app_id'], APP_INFO['secret_key'], AUTH['refresh_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = query_api(endpoint=\"sites\")\n",
    "arg_site_id = list(filter(lambda x: x[\"name\"] == \"Argentina\", sites))[0]['id']\n",
    "categories = query_api(endpoint=\"sites\", filter_id=arg_site_id, attr=\"categories\")\n",
    "categories = list(filter(lambda x: x[\"name\"] != \"Servicios\", categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = get_categories_subcategories(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(endpoint=\"sites\",\n",
    "            filter_id=arg_site_id,\n",
    "            attr=\"search\",\n",
    "            full_cats=cats,\n",
    "            include_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_all_data(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un poco la estructura que tienen nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Report\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminemos algunas variables:\n",
    "- site_id: para este analisis nos vamos a estar concentrando unicamente en publicaciones de Argentina\n",
    "- id, link y permalink: valores unicos\n",
    "- attributes: para este analisis y por simplicidad, eliminemosla, dado que su estructura es compleja y observandolo en detalle, el attributo mas interesante puede llegar a ser brand y no esta presente siempre\n",
    "- seller: seller tiene una infinidad de variables, de las cuales muchas son NA y otras son posibles de conseguir en la respuesta base (city, state, etc). Nos quedamos solo con el id y su status.\n",
    "- installments: currency ya esta declarada en las variables regulares, y rate correlaciona perfecto con quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dframe):\n",
    "    # Remove undesired columns\n",
    "    df = dframe.copy()\n",
    "    undesired_seller = [col for col in df if (col.startswith(\"seller\") and col not in (\"seller.id\", \"seller.power_seller_status\"))]\n",
    "    undesired_location = [col for col in df if col.startswith(\"location\")]\n",
    "    undesired_shipping = [\"shipping.tags\", \"shipping.mode\"]\n",
    "    undesired_address = [\"address.state_name\", \"address.city_id\", \"address.area_code\", \"address.phone1\"] # El state_id aparece siempre y no requiere tratamiento de strings. Por lo contrario el city_name tiene mas data que city_id\n",
    "    undesired_installments = [\"installments.currency_id\", \"installments.rate\"]\n",
    "    undesired_regular = [\"id\", \"site_id\", \"permalink\", \"thumbnail\", \"title\", \"attributes\", \"stop_time\", \"installments\"]\n",
    "    undesired_cols = undesired_seller + undesired_shipping + undesired_address + undesired_installments + undesired_regular + undesired_location\n",
    "    df.drop(undesired_cols, axis=1, inplace=True)\n",
    "    # Create columns\n",
    "    df['has_discount'] = df['original_price'].notnull()\n",
    "    df['discount'] = ((df['original_price'] - df['price'])/ df['original_price']).fillna(0)\n",
    "    df.drop('original_price', axis=1, inplace=True)\n",
    "    # Ajusto precios dolarizados\n",
    "    df[\"price\"] = np.where(df['currency_id'] == \"USD\", df['price'] * PRECIO_DOLAR , df['price'])\n",
    "    df.drop(\"currency_id\", axis=1, inplace=True)\n",
    "    # Unpack tags\n",
    "    df[\"tags\"] = df[\"tags\"].apply(lambda x: \" \".join(x)).apply(lambda x: x.replace(\"-\", \"_\"))\n",
    "    cvect = CountVectorizer()\n",
    "    tags = cvect.fit_transform(df[\"tags\"]).toarray()\n",
    "    for i, col in enumerate(cvect.get_feature_names()):\n",
    "        df[col] = tags[:, i]\n",
    "    df.drop('tags', axis=1, inplace=True)\n",
    "    #Transform city_address name\n",
    "    df['address.city_name'] = df['address.city_name'].apply(lambda x: x.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_df['sold_quantity']\n",
    "X = final_df.drop('sold_quantity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"price\", \"discount\", \"available_quantity\", \"installments.quantity\", \"installments.amount\"]\n",
    "X[numeric_features] = X[numeric_features].apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "categorical_features = list(X.drop(numeric_features, axis=1).columns)\n",
    "X[categorical_features] = X[categorical_features].applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    [('imputer', SimpleImputer(strategy='median'))]\n",
    ")\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='__')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LGBMRegressor()\n",
    "pipe = Pipeline([('preprocessor', preprocessor), ('estimator', estimator)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_feature_names = pipe.steps[0][1].transformers_[1][1].steps[1][1].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pipe.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(numeric_features) + list(ohe_feature_names)\n",
    "f_i = list(zip(cols, feature_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(f_i, columns=[\"feature_names\", \"importance\"]).sort_values('importance', ascending=False).reset_index(drop=True).query(\"importance > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pipe.steps[1][1].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=4)\n",
    "\n",
    "scores = cross_val_score(pipe, X_train, y_train, cv = cv, scoring='neg_mean_absolute_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
